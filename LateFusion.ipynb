{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet34, EfficientNet_B1_Weights\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchmetrics.regression import KendallRankCorrCoef,PearsonCorrCoef\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn import preprocessing\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import AutoAugmentPolicy, AutoAugment, RandomPerspective, RandomAffine, ElasticTransform, Grayscale\n",
    "from copy import copy\n",
    "\n",
    "import urllib\n",
    "import cv2\n",
    "\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Model based on Z. Zou, X. Zhang, H. Liu, Z. Li, A. Hussain, i J. Li, „A novel multimodal fusion network based on a joint coding model for lane line segmentation”. http://arxiv.org/abs/2103.11114"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27274009edec6618"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_root = \"./dataStructure/training\"\n",
    "validation_root=\"./dataStructure/validation\"\n",
    "txt_file_train = \"label_2\"\n",
    "\n",
    "thing_classes = ['Pedestrian']\n",
    "train_img_count = 5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e5014371fd59bd2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_pedestrian_label(data_root, txt_folder):\n",
    "    annotations = []\n",
    "    labels_folder =os.path.join(data_root, txt_folder)\n",
    "    for file in os.listdir(labels_folder):\n",
    "        file_id = file[:-4]\n",
    "        file_path = os.path.join(labels_folder,file)\n",
    "        with open(file_path, 'r') as opened_file:\n",
    "            bb_list = []\n",
    "            for line in opened_file:\n",
    "              coordinates = line.split()\n",
    "              if coordinates == []:\n",
    "                continue\n",
    "              class_name, _, _,_, xmin, ymin, xmax, ymax, _, _ ,_ , _, _, _, _= map(str, coordinates)\n",
    "              if class_name in thing_classes:\n",
    "                xmin = int(float(xmin))\n",
    "                ymin = int(float(ymin))\n",
    "                xmax = int(float(xmax))\n",
    "                ymax = int(float(ymax))\n",
    "                bb_list.append((xmin,ymin,xmax,ymax))\n",
    "        annotations.append((file_id,bb_list))\n",
    "\n",
    "    return annotations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ead4c31fd03f4e1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data_dict = get_pedestrian_label(data_root, txt_file_train)\n",
    "import random\n",
    "\n",
    "for d in random.sample(train_data_dict, 1):\n",
    "    image_path = os.path.join(data_root, \"image_2\", d[0] + \".png\")\n",
    "    img = cv2.imread(image_path)\n",
    "    h1, w1, _ = img.shape\n",
    "    for bb in d[1]:\n",
    "      x1 = bb[0]\n",
    "      x2 = bb[2]\n",
    "      y1= bb[1]\n",
    "      y2 = bb[3]\n",
    "      cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)  \n",
    "\n",
    "    plt.figure(figsize = (12, 12))\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "for d in random.sample(train_data_dict, 1):\n",
    "    image_path = os.path.join(data_root, \"densec\", d[0] + \".png\")\n",
    "    imgdense = cv2.imread(image_path)\n",
    "    imgdense = cv2.resize(imgdense, (w1, h1))\n",
    "    for bb in d[1]:\n",
    "        x1, y1, x2, y2 = bb\n",
    "        cv2.rectangle(imgdense, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "    plt.figure(figsize = (12, 12))\n",
    "    plt.imshow(imgdense)\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a78d6ded80a392a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def writeBboxColor(imagename,train_data_dict):\n",
    "  for label in train_data_dict:\n",
    "    if label[0]==imagename:\n",
    "      image_path = os.path.join(data_root, \"image_2\", imagename + \".png\")\n",
    "      img = Image.open(image_path)\n",
    "      return img"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "858f101ae0eac7a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def writeBboxDense(imagename,train_data_dict):\n",
    "  for label in train_data_dict:\n",
    "    if label[0]==imagename:\n",
    "      image_path = os.path.join(data_root, \"densec\", imagename + \".png\")\n",
    "      img = Image.open(image_path)\n",
    "      return img"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "faeec5de0bee0e20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class kitti_loader:\n",
    "    def __init__(self, directory,transform):\n",
    "            txt_file_train = \"label_2\"\n",
    "            self.root_dir = directory\n",
    "            self.transform = transform\n",
    "            self.train_data_dict = get_pedestrian_label(data_root, txt_file_train) \n",
    "    def __len__(self):\n",
    "            return len(os.listdir(self.root_dir+\"/calib\"))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        formatedidx=f\"{idx:06}\"\n",
    "        if torch.is_tensor(formatedidx):\n",
    "            formatedidx = idx.tolist()\n",
    "        image = writeBboxColor(formatedidx,self.train_data_dict)\n",
    "        dense = writeBboxDense(formatedidx,self.train_data_dict)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            dense = self.transform(dense)\n",
    "        labelList=[]\n",
    "        for label in train_data_dict:\n",
    "                if label[0]==formatedidx:\n",
    "                    if label[1]!=[]:\n",
    "                        labelList.append(label[1][0])\n",
    "                    else:\n",
    "                        labelList.append((0,0,0,0))\n",
    "        labelList=torch.tensor(labelList)\n",
    "        return image,dense,labelList"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc5954431efa20af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    #IMAGE RGB\n",
    "        # Block A pink\n",
    "        self.A_block_conv = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.A_block_bn = nn.BatchNorm2d(64)\n",
    "        self.A_block_relu = nn.ReLU()\n",
    "\n",
    "        # Block B red\n",
    "        self.resnet34 = models.resnet34(pretrained=False)\n",
    "        self.B_resnet34= nn.Sequential(*list(self.resnet34.children())[:-2])\n",
    "        self.B_resnet34[0] = nn.Conv2d(64, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.B_resnet34 = nn.Sequential(\n",
    "            self.B_resnet34,\n",
    "            nn.Conv2d(512, 64, kernel_size=7, stride=2, padding=3)\n",
    "        )\n",
    "\n",
    "        # Block C red\n",
    "        self.resnet34 = models.resnet34(pretrained=False)\n",
    "        self.C_resnet34= nn.Sequential(*list(self.resnet34.children())[:-2])\n",
    "        self.C_resnet34[0] = nn.Conv2d(64, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.C_resnet34 = nn.Sequential(\n",
    "            self.C_resnet34,\n",
    "            nn.Conv2d(512, 128, kernel_size=7, stride=2, padding=3)\n",
    "        )\n",
    "        # Block D pink\n",
    "        self.D_block_conv = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.D_block_bn = nn.BatchNorm2d(256)\n",
    "        self.D_block_relu = nn.ReLU()\n",
    "\n",
    "        # Block E pink\n",
    "        self.E1_block_conv = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.E1_block_bn = nn.BatchNorm2d(512)\n",
    "        self.E1_block_relu = nn.ReLU()\n",
    "\n",
    "        self.E2_block_conv = nn.Conv2d(in_channels=512, out_channels=384, kernel_size=3, padding=1)\n",
    "        self.E2_block_bn = nn.BatchNorm2d(384)\n",
    "        self.E2_block_relu = nn.ReLU()\n",
    "\n",
    "        #block F blue\n",
    "        self.F_block_convt = nn.ConvTranspose2d(in_channels=384, out_channels=64, kernel_size=3, padding=1)   # out tymczasowo na 10 bo test na cifarze\n",
    "        self.F_block_bn = nn.BatchNorm2d(64)\n",
    "        self.F_block_relu = nn.ReLU()\n",
    "\n",
    "    #POINTS\n",
    "        #block G pink\n",
    "        self.G_block_conv = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.G_block_bn = nn.BatchNorm2d(64)\n",
    "        self.G_block_relu = nn.ReLU()\n",
    "\n",
    "        #block H red\n",
    "        self.resnet34 = models.resnet34(pretrained=False)\n",
    "        self.H_resnet34= nn.Sequential(*list(self.resnet34.children())[:-2])\n",
    "        self.H_resnet34[0] = nn.Conv2d(64, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.H_resnet34 = nn.Sequential(\n",
    "            self.H_resnet34,\n",
    "            nn.Conv2d(512, 64, kernel_size=7, stride=2, padding=3)\n",
    "        )\n",
    "\n",
    "        #block I red\n",
    "        self.resnet34 = models.resnet34(pretrained=False)\n",
    "        self.I_resnet34= nn.Sequential(*list(self.resnet34.children())[:-2])\n",
    "        self.I_resnet34[0] = nn.Conv2d(64, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.I_resnet34 = nn.Sequential(\n",
    "            self.I_resnet34,\n",
    "            nn.Conv2d(512, 128, kernel_size=7, stride=2, padding=3)\n",
    "        )\n",
    "\n",
    "        #block J pink\n",
    "        self.J_block_conv = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.J_block_bn = nn.BatchNorm2d(256)\n",
    "        self.J_block_relu = nn.ReLU()\n",
    "\n",
    "        #block K pink\n",
    "        self.K1_block_conv = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.K1_block_bn = nn.BatchNorm2d(512)\n",
    "        self.K1_block_relu = nn.ReLU()\n",
    "\n",
    "        self.K2_block_conv = nn.Conv2d(in_channels=512, out_channels=384, kernel_size=3, padding=1)\n",
    "        self.K2_block_bn = nn.BatchNorm2d(384)\n",
    "        self.K2_block_relu = nn.ReLU()\n",
    "\n",
    "        #block L blue\n",
    "        self.L_block_convt = nn.ConvTranspose2d(in_channels=384, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.L_block_bn = nn.BatchNorm2d(64)\n",
    "        self.L_block_relu = nn.ReLU()\n",
    "\n",
    "        #block M red/pink\n",
    "        self.resnet34 = models.resnet34(pretrained=False)\n",
    "        self.M1_resnet34= nn.Sequential(*list(self.resnet34.children())[:-2])\n",
    "        self.M1_resnet34[0] = nn.Conv2d(256, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.M1_resnet34 = nn.Sequential(\n",
    "            self.M1_resnet34,\n",
    "            nn.Conv2d(512, 192, kernel_size=7, stride=2, padding=3)\n",
    "        )\n",
    "        self.M2_block_conv = nn.Conv2d(in_channels=320, out_channels=320, kernel_size=3, padding=1)\n",
    "        self.M2_block_bn = nn.BatchNorm2d(320)\n",
    "        self.M2_block_relu = nn.ReLU()\n",
    "\n",
    "        #block N red/blue\n",
    "        self.N_in_block=nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.N1_resnet34= nn.Sequential(*list(self.resnet34.children())[:-2])\n",
    "        self.N1_resnet34[0] = nn.Conv2d(448, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.N1_resnet34 = nn.Sequential(\n",
    "            self.N1_resnet34,\n",
    "            nn.Conv2d(512, 192, kernel_size=7, stride=2, padding=3)\n",
    "        )\n",
    "        self.N2_block_convt = nn.ConvTranspose2d(in_channels=192, out_channels=192, kernel_size=3, padding=1)\n",
    "        self.N2_block_bn = nn.BatchNorm2d(192)\n",
    "        self.N2_block_relu = nn.ReLU()\n",
    "\n",
    "        #block O pink/blue\n",
    "        self.O0_block_conv = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=34, padding=1)\n",
    "        self.O1_block_conv = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.O1_block_bn = nn.BatchNorm2d(256)\n",
    "        self.O1_block_relu = nn.ReLU()\n",
    "\n",
    "        self.O2_block_convt = nn.ConvTranspose2d(in_channels=320, out_channels=192, kernel_size=3, padding=1)\n",
    "        self.O2_block_bn = nn.BatchNorm2d(192)\n",
    "        self.O2_block_relu = nn.ReLU()\n",
    "\n",
    "        #block P blue\n",
    "        self.P_block_convt = nn.ConvTranspose2d(in_channels=192, out_channels=1, kernel_size=3, padding=1)   \n",
    "        self.P_block_bn = nn.BatchNorm2d(1)\n",
    "        self.P_block_relu = nn.ReLU()\n",
    "        self.P_avg_pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(1, 1),  # Since your last layer outputs a tensor with 4 channels\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.bbox_regressor = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1, 4)  \n",
    "        )\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "\n",
    "        outA = self.A_block_relu(self.A_block_bn(self.A_block_conv(x)))\n",
    "        outB = self.B_resnet34(outA)\n",
    "        outC = self.C_resnet34(outB)\n",
    "        outD = self.D_block_relu(self.D_block_bn(self.D_block_conv(outC)))\n",
    "        outE = self.E2_block_relu(self.E2_block_bn(self.E2_block_conv(self.E1_block_relu(self.E1_block_bn(self.E1_block_conv(torch.cat([outD, outD], dim=1)))))))\n",
    "        outF = self.F_block_relu(self.F_block_bn(self.F_block_convt(outE)))\n",
    "\n",
    "        outG = self.G_block_relu(self.A_block_bn(self.A_block_conv(y)))\n",
    "        outH = self.H_resnet34(outG)\n",
    "        outI = self.I_resnet34(outH)\n",
    "        outJ = self.J_block_relu(self.J_block_bn(self.J_block_conv(outI)))\n",
    "        outK = self.K2_block_relu(self.K2_block_bn(self.K2_block_conv(self.K1_block_relu(self.K1_block_bn(self.K1_block_conv(torch.cat([outJ, outJ], dim=1)))))))\n",
    "        outL = self.L_block_relu(self.L_block_bn(self.L_block_convt(outK)))\n",
    "\n",
    "        outM = self.M2_block_relu(self.M2_block_bn(self.M2_block_conv(torch.cat([self.M1_resnet34(torch.cat([outC, outI], dim=1)), outF, outL], dim=1))))\n",
    "\n",
    "        outH_pooled = self.N_in_block(outH)\n",
    "        outB_pooled = self.N_in_block(outB)\n",
    "\n",
    "        outN = self.N2_block_relu(self.N2_block_bn(self.N2_block_convt(self.N1_resnet34(torch.cat([outM, outH_pooled, outB_pooled], dim=1)))))\n",
    "\n",
    "        outAA = self.O0_block_conv(outA)\n",
    "        outGG = self.O0_block_conv(outG)\n",
    "\n",
    "        outN_upsampled = F.interpolate(outN, size=(193, 193), mode='bilinear', align_corners=False)\n",
    "        outO = self.O2_block_relu(self.O2_block_bn(self.O2_block_convt(torch.cat([outAA, self.O1_block_relu(self.O1_block_bn(self.O1_block_conv(torch.cat([outN_upsampled, outGG], dim=1))))], dim=1))))\n",
    "\n",
    "        outP = self.P_avg_pool(self.P_block_relu(self.P_block_bn(self.P_block_convt(outO))))\n",
    "        #print('outP',outP.size())\n",
    "        outR=self.classifier(outP)\n",
    "\n",
    "        bbox_output = self.bbox_regressor(outP)\n",
    "        return outR,bbox_output\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "# print(model)\n",
    "\n",
    "#summary(model, input_size=((32, 3, 128, 256), (32, 3, 128, 256)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1478026f238debd6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logdir = \"logs\"\n",
    "experiment = 'late'\n",
    "\n",
    "# Directory where logs will be saved. \n",
    "log_dir = os.path.join(logdir, experiment)\n",
    "\n",
    "# initiate tensorboard summary writer\n",
    "tb_writer = SummaryWriter(\n",
    "    log_dir = log_dir,\n",
    "    comment = \"EarlyFusion\"\n",
    ")\n",
    "train_accuracy_tag = 'accuracy/train'\n",
    "validation_accuracy_tag = 'accuracy/validation'\n",
    "train_loss_tag = 'loss/train'\n",
    "validation_loss_tag = 'loss/validation'\n",
    "training_ROC_tag='ROC/train'\n",
    "validation_ROC_tag='ROC/validation'\n",
    "training_pearson_tag='pearson/training'\n",
    "validation_pearson_tag='pearson/validation'\n",
    "training_kendal_tag='kendal/training'\n",
    "validation_kendal_tag='kendal/validation'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a7ad8bd763a3a9b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_model(model, device,epoch, model_dir='models', ):\n",
    "    model_file_name=f'earlyfusion{epoch}.pth'\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "\n",
    "    if device == 'cuda':\n",
    "        model.to('cpu')\n",
    "\n",
    "    # save the state_dict\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    # transfer the model to gpu.\n",
    "    if device == 'cuda':\n",
    "        model.to('cuda')\n",
    "\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d791d0de336d6c36"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Mean= [0.485, 0.456, 0.406]\n",
    "Std= [0.229, 0.224, 0.225]\n",
    "common_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(Mean, Std)\n",
    "    ])\n",
    "\n",
    "trainset = kitti_loader(directory=data_root,transform=common_transforms)\n",
    "valset = kitti_loader(directory=validation_root,transform=common_transforms)\n",
    "\n",
    "batch_size = 2\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "valloader= torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr = 0.0001)\n",
    "\n",
    "num_epochs = 100\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)\n",
    "\n",
    "kendall = KendallRankCorrCoef(num_outputs=4).cuda()\n",
    "pearson = PearsonCorrCoef(num_outputs=4).cuda()\n",
    "\n",
    "t_begin = time.time()\n",
    "criterion = nn.MSELoss()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    batch_kendall = []\n",
    "    batch_pearson = []\n",
    "    for i, data in enumerate(trainloader):\n",
    "        input1, input2,label = data\n",
    "\n",
    "        input1 = input1.cuda()\n",
    "        input2 = input2.cuda()\n",
    "        labels = label.cuda().squeeze()\n",
    "        optimizer.zero_grad()\n",
    "        outputs_class,outputs_bbox  = model(input1, input2)\n",
    "\n",
    "        loss = criterion(outputs_bbox, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if loss.item!=None:\n",
    "            running_loss += loss.item()\n",
    "\n",
    "\n",
    "        batch_kendall.append(kendall (outputs_bbox, labels.float()))\n",
    "        batch_pearson.append(pearson(outputs_bbox, labels.float()))\n",
    "\n",
    "    print(batch_kendall)\n",
    "    kendall_sum = torch.stack(batch_kendall).sum(dim=0)  # sum size of batch\n",
    "    kendall_mean = kendall_sum / len(trainloader)  # devide len batch\n",
    "    kendall_mean_scalar = torch.mean(kendall_mean).item()  \n",
    "    print(\"kendall_mean_scalar\",kendall_mean_scalar)\n",
    "    pearson_sum = torch.stack(batch_pearson).sum(dim=0)\n",
    "    pearson_mean = pearson_sum / len(trainloader)\n",
    "    pearson_mean_scalar = torch.mean(pearson_mean).item()\n",
    "    print(\"pearson_mean_scalar\",pearson_mean_scalar)\n",
    "    tb_writer.add_scalar(tag=train_loss_tag, \n",
    "             scalar_value=running_loss,\n",
    "             global_step=epoch)\n",
    "    \n",
    "    tb_writer.add_scalar(tag=training_kendal_tag, \n",
    "             scalar_value=kendall_mean_scalar,\n",
    "             global_step=epoch)\n",
    "    tb_writer.add_scalar(tag=training_pearson_tag, \n",
    "             scalar_value=pearson_mean_scalar,\n",
    "             global_step=epoch)\n",
    "\n",
    "    elapsed_time = time.time() - t_begin\n",
    "    speed_epoch = elapsed_time / (epoch + 1)\n",
    "    eta = speed_epoch * num_epochs - elapsed_time\n",
    "\n",
    "    print(\n",
    "        \"Elapsed {:.2f}s, {:.2f} s/epoch, ets {:.2f}s\".format(\n",
    "            elapsed_time, speed_epoch, eta\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1},Loss: {running_loss} \")\n",
    "\n",
    "    if epoch % 5 == 0 :\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        \n",
    "        pearson_val = PearsonCorrCoef(num_outputs=4).cuda()\n",
    "        kendall_val = KendallRankCorrCoef(num_outputs=4).cuda()\n",
    "        batch_kendall_val = []\n",
    "        batch_pearson_val = []\n",
    "        for batch_idx, (data) in enumerate(valloader):\n",
    "            input1, input2,label = data\n",
    "            input1 = input1.cuda()\n",
    "            input2 = input2.cuda()\n",
    "            labels = label.cuda().squeeze()\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                outputs_class,outputs_bbox  = model(input1, input2)\n",
    "\n",
    "            batch_kendall_val.append(kendall (outputs_bbox, labels.float()))\n",
    "            batch_pearson_val.append(pearson(outputs_bbox, labels.float()))\n",
    "        \n",
    "        kendall_sum_val = torch.stack(batch_kendall_val).sum(dim=0)\n",
    "        kendall_mean_val = kendall_sum_val / len(valloader)\n",
    "        kendall_mean_val_scalar = torch.mean(kendall_mean_val).item()\n",
    "        \n",
    "        pearson_sum_val = torch.stack(batch_pearson_val).sum(dim=0)\n",
    "        pearson_mean_val= pearson_sum_val/ len(valloader)\n",
    "        pearson_mean_val_scalar = torch.mean(pearson_sum_val).item()\n",
    "\n",
    "        tb_writer.add_scalar(tag=validation_loss_tag, \n",
    "             scalar_value=val_loss,\n",
    "             global_step=epoch)\n",
    "        tb_writer.add_scalar(tag=validation_kendal_tag, \n",
    "                 scalar_value=kendall_mean_val_scalar,\n",
    "                 global_step=epoch)\n",
    "        tb_writer.add_scalar(tag=validation_pearson_tag, \n",
    "                 scalar_value=pearson_mean_val_scalar,\n",
    "                 global_step=epoch)\n",
    "\n",
    "        save_model(model, device=device,epoch=epoch)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Finished Training\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4b2fcd98a2865228"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c7f15228e2905826"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
