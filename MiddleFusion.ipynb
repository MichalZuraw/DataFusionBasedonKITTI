{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet34, EfficientNet_B1_Weights\n",
    "from torchvision.datasets import CIFAR10\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics.regression import KendallRankCorrCoef,PearsonCorrCoef\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import AutoAugmentPolicy, AutoAugment, RandomPerspective, RandomAffine, ElasticTransform, Grayscale\n",
    "from copy import copy\n",
    "\n",
    "import urllib\n",
    "import cv2\n",
    "\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Model based on Z. Zou, X. Zhang, H. Liu, Z. Li, A. Hussain, i J. Li, „A novel multimodal fusion network based on a joint coding model for lane line segmentation”. http://arxiv.org/abs/2103.11114"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1640ff9835ff0d07"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_root = \"./dataStructure/training\"\n",
    "validation_root=\"./dataStructure/validation\"\n",
    "txt_file_train = \"label_2\"\n",
    "\n",
    "thing_classes = ['Pedestrian']\n",
    "train_img_count = 5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3123bfbbe4fc9789"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_pedestrian_label(data_root, txt_folder):\n",
    "    annotations = []\n",
    "    labels_folder =os.path.join(data_root, txt_folder)\n",
    "    for file in os.listdir(labels_folder):\n",
    "        file_id = file[:-4]\n",
    "        file_path = os.path.join(labels_folder,file)\n",
    "        with open(file_path, 'r') as opened_file:\n",
    "            bb_list = []\n",
    "            for line in opened_file:\n",
    "              coordinates = line.split()\n",
    "              if coordinates == []:\n",
    "                continue\n",
    "              class_name, _, _,_, xmin, ymin, xmax, ymax, _, _ ,_ , _, _, _, _= map(str, coordinates)\n",
    "              if class_name in thing_classes:\n",
    "                xmin = int(float(xmin))\n",
    "                ymin = int(float(ymin))\n",
    "                xmax = int(float(xmax))\n",
    "                ymax = int(float(ymax))\n",
    "                bb_list.append((xmin,ymin,xmax,ymax))\n",
    "        annotations.append((file_id,bb_list))\n",
    "\n",
    "    return annotations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a36f5c435d9fadce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data_dict = get_pedestrian_label(data_root, txt_file_train)\n",
    "import random\n",
    "\n",
    "for d in random.sample(train_data_dict, 1):\n",
    "    image_path = os.path.join(data_root, \"image_2\", d[0] + \".png\")\n",
    "    img = cv2.imread(image_path)\n",
    "    h1, w1, _ = img.shape\n",
    "    for bb in d[1]:\n",
    "      x1 = bb[0]\n",
    "      x2 = bb[2]\n",
    "      y1= bb[1]\n",
    "      y2 = bb[3]\n",
    "      cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)  \n",
    "\n",
    "    plt.figure(figsize = (12, 12))\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "for d in random.sample(train_data_dict, 1):\n",
    "    image_path = os.path.join(data_root, \"densec\", d[0] + \".png\")\n",
    "    imgdense = cv2.imread(image_path)\n",
    "    imgdense = cv2.resize(imgdense, (w1, h1))\n",
    "    for bb in d[1]:\n",
    "        x1, y1, x2, y2 = bb\n",
    "        cv2.rectangle(imgdense, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "    plt.figure(figsize = (12, 12))\n",
    "    plt.imshow(imgdense)\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea4920b8831923d4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def writeBboxColor(imagename,train_data_dict):\n",
    "  for label in train_data_dict:\n",
    "    if label[0]==imagename:\n",
    "      image_path = os.path.join(data_root, \"image_2\", imagename + \".png\")\n",
    "      img = Image.open(image_path)\n",
    "      return img"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f69a0b29d4b0112"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def writeBboxDense(imagename,train_data_dict):\n",
    "  for label in train_data_dict:\n",
    "    if label[0]==imagename:\n",
    "      image_path = os.path.join(data_root, \"densec\", imagename + \".png\")\n",
    "      img = Image.open(image_path)\n",
    "      return img"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9d093c20f2a2962"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class kitti_loader:\n",
    "    def __init__(self, directory,transform):\n",
    "            txt_file_train = \"label_2\"\n",
    "            self.root_dir = directory\n",
    "            self.transform = transform\n",
    "            self.train_data_dict = get_pedestrian_label(data_root, txt_file_train) \n",
    "    def __len__(self):\n",
    "            return len(os.listdir(self.root_dir+\"/calib\"))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        formatedidx=f\"{idx:06}\"\n",
    "        if torch.is_tensor(formatedidx):\n",
    "            formatedidx = idx.tolist()\n",
    "        image = writeBboxColor(formatedidx,self.train_data_dict)\n",
    "        dense = writeBboxDense(formatedidx,self.train_data_dict)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            dense = self.transform(dense)\n",
    "        labelList=[]\n",
    "        for label in train_data_dict:\n",
    "                if label[0]==formatedidx:\n",
    "                    if label[1]!=[]:\n",
    "                        labelList.append(label[1][0])\n",
    "                    else:\n",
    "                        labelList.append((0,0,0,0))\n",
    "        labelList=torch.tensor(labelList)\n",
    "        return image,dense,labelList"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7b53b3da49c8cd7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logdir = \"logs\"\n",
    "experiment = 'middle'\n",
    "\n",
    "# Directory where logs will be saved. \n",
    "log_dir = os.path.join(logdir, experiment)\n",
    "\n",
    "# initiate tensorboard summary writer\n",
    "tb_writer = SummaryWriter(\n",
    "    log_dir = log_dir,\n",
    "    comment = \"MiddleFusion\"\n",
    ")\n",
    "train_accuracy_tag = 'accuracy/train'\n",
    "validation_accuracy_tag = 'accuracy/validation'\n",
    "train_loss_tag = 'loss/train'\n",
    "validation_loss_tag = 'loss/validation'\n",
    "training_ROC_tag='ROC/train'\n",
    "validation_ROC_tag='ROC/validation'\n",
    "training_pearson_tag='pearson/training'\n",
    "validation_pearson_tag='pearson/validation'\n",
    "training_kendal_tag='kendal/training'\n",
    "validation_kendal_tag='kendal/validation'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2fab1c82e72d0e3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_model(model, device,epoch, model_dir='models', ):\n",
    "    model_file_name=f'earlyfusion{epoch}.pth'\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "\n",
    "    if device == 'cuda':\n",
    "        model.to('cpu')\n",
    "\n",
    "    # save the state_dict\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    # transfer the model to gpu.\n",
    "    if device == 'cuda':\n",
    "        model.to('cuda')\n",
    "\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "493b5dcd3d707b64"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Block A pink\n",
    "        self.A_block_conv = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.A_block_bn = nn.BatchNorm2d(64)\n",
    "        self.A_block_relu = nn.ReLU()\n",
    "\n",
    "        # Block B pink\n",
    "        self.B_block_conv = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.B_block_bn = nn.BatchNorm2d(64)\n",
    "        self.B_block_relu = nn.ReLU()\n",
    "\n",
    "        # Block C red\n",
    "        self.resnet34 = models.resnet34(pretrained=False)\n",
    "        self.C_resnet34= nn.Sequential(*list(self.resnet34.children())[:-2])\n",
    "        self.C_resnet34[0] = nn.Conv2d(64, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.C_resnet34 = nn.Sequential(\n",
    "            self.C_resnet34,\n",
    "            nn.Conv2d(512, 64, kernel_size=7, stride=2, padding=3)\n",
    "        )\n",
    "\n",
    "        # Block D red\n",
    "        self.D_resnet34 = nn.Sequential(*list(self.resnet34.children())[:-2])\n",
    "        self.D_resnet34[0] = nn.Conv2d(64, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.D_resnet34 = nn.Sequential(\n",
    "            self.D_resnet34,\n",
    "            nn.Conv2d(512, 64, kernel_size=7, stride=2, padding=3)\n",
    "        )\n",
    "\n",
    "        #block E red\n",
    "        self.E_resnet34 = nn.Sequential(*list(self.resnet34.children())[:-2])\n",
    "        self.E_resnet34[0] = nn.Conv2d(64, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.E_resnet34 = nn.Sequential(\n",
    "            self.E_resnet34,\n",
    "            nn.Conv2d(512, 128, kernel_size=7, stride=2, padding=3)\n",
    "        )\n",
    "\n",
    "        #block F red\n",
    "        self.F_resnet34 = nn.Sequential(*list(self.resnet34.children())[:-2])\n",
    "        self.F_resnet34[0] = nn.Conv2d(64, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.F_resnet34 = nn.Sequential(\n",
    "            self.F_resnet34,\n",
    "            nn.Conv2d(512, 128, kernel_size=7, stride=2, padding=3)\n",
    "        )\n",
    "\n",
    "        #block G red\n",
    "        self.G1_resnet34 = nn.Sequential(*list(self.resnet34.children())[:-2])\n",
    "        self.G1_resnet34[0] = nn.Conv2d(256, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.G1_resnet34 = nn.Sequential(\n",
    "            self.G1_resnet34,\n",
    "            nn.Conv2d(512, 64, kernel_size=7, stride=2, padding=3)\n",
    "        )\n",
    "        self.G2_resnet34 = nn.Sequential(*list(self.resnet34.children())[:-2])\n",
    "        self.G2_resnet34[0] = nn.Conv2d(64, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.G2_resnet34 = nn.Sequential(\n",
    "            self.G2_resnet34,\n",
    "            nn.Conv2d(512, 256, kernel_size=7, stride=2, padding=3)\n",
    "        )\n",
    "\n",
    "        #block H pink\n",
    "        self.H_block_conv = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.H_block_bn = nn.BatchNorm2d(256)\n",
    "        self.H_block_relu = nn.ReLU()\n",
    "\n",
    "        #block I pinkpink\n",
    "        self.I1_block_conv = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.I1_block_bn = nn.BatchNorm2d(256)\n",
    "        self.I1_block_relu = nn.ReLU()\n",
    "        self.I2_block_conv = nn.Conv2d(in_channels=512, out_channels=384, kernel_size=3, padding=1)\n",
    "        self.I2_block_bn = nn.BatchNorm2d(384)\n",
    "        self.I2_block_relu = nn.ReLU()\n",
    "\n",
    "        #block J redblue\n",
    "        self.J_resnet34 = nn.Sequential(*list(self.resnet34.children())[:-2])\n",
    "        self.J_resnet34[0] = nn.Conv2d(640, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.J_resnet34 = nn.Sequential(\n",
    "            self.J_resnet34,\n",
    "            nn.Conv2d(512, 64, kernel_size=7, stride=2, padding=3)\n",
    "        )\n",
    "        self.J_block_convt = nn.ConvTranspose2d(in_channels=64,out_channels= 320, kernel_size=3, padding=1)\n",
    "        self.J_block_bn = nn.BatchNorm2d(320)\n",
    "        self.J_block_relu = nn.ReLU()\n",
    "\n",
    "        #block K redblue\n",
    "        self.K_in_block=nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.K_resnet34 = nn.Sequential(*list(self.resnet34.children())[:-2])\n",
    "        self.K_resnet34[0] = nn.Conv2d(448, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.K_resnet34 = nn.Sequential(\n",
    "            self.K_resnet34,\n",
    "            nn.Conv2d(512, 128, kernel_size=7, stride=2, padding=3)\n",
    "        )\n",
    "        self.K_block_convt = nn.ConvTranspose2d(in_channels=128,out_channels= 192, kernel_size=3, padding=1)\n",
    "        self.K_block_bn = nn.BatchNorm2d(192)\n",
    "        self.K_block_relu = nn.ReLU()\n",
    "\n",
    "        #block L pinkblue\n",
    "        self.L0_block_conv = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=34, padding=1)\n",
    "        self.L1_block_conv = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.L1_block_bn = nn.BatchNorm2d(256)\n",
    "        self.L1_block_relu = nn.ReLU()\n",
    "        self.L2_block_convt = nn.ConvTranspose2d(in_channels=320, out_channels= 192, kernel_size=3, padding=1)\n",
    "        self.L2_block_bn = nn.BatchNorm2d(192)\n",
    "        self.L2_block_relu = nn.ReLU()\n",
    "\n",
    "        #block M blue\n",
    "        self.M_block_convt = nn.ConvTranspose2d(in_channels=192, out_channels=4, kernel_size=3, padding=1)\n",
    "        self.M_block_bn = nn.BatchNorm2d(4)\n",
    "        self.M_block_relu = nn.ReLU()\n",
    "        self.M_avg_pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(4, 2),  # Since your last layer outputs a tensor with 4 channels\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.bbox_regressor = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(4, 4)  \n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x, y):\n",
    "\n",
    "        outA = self.A_block_relu(self.A_block_bn(self.A_block_conv(x)))\n",
    "        #print(\"outA\", outA.size())\n",
    "        outC = self.C_resnet34(outA)\n",
    "        #print(\"outC\", outC.size())\n",
    "        outE = self.E_resnet34(outC)\n",
    "        #print(\"outE\", outE.size())\n",
    "\n",
    "        outB = self.B_block_relu(self.B_block_bn(self.B_block_conv(y)))\n",
    "        #print(\"outB\", outB.size())\n",
    "        outD = self.D_resnet34(outB)\n",
    "        #print(\"outD\", outD.size())\n",
    "        outF = self.F_resnet34(outD)\n",
    "        #print(\"outF\", outF.size())\n",
    "\n",
    "        outG = self.G2_resnet34(self.G1_resnet34(torch.cat([outE, outF], dim=1)))\n",
    "        #print(\"outG\", outG.size())\n",
    "\n",
    "        outH = self.H_block_relu(self.H_block_bn(self.H_block_conv(outG)))\n",
    "        #print(\"outH\", outH.size())\n",
    "\n",
    "        outI = self.I2_block_relu(self.I2_block_bn(self.I2_block_conv(torch.cat([self.I1_block_relu(self.I1_block_bn(self.I1_block_conv(outH))), outH], dim=1))))\n",
    "        #print(\"outI\", outI.size())\n",
    "\n",
    "        outJ = self.J_block_relu(self.J_block_bn(self.J_block_convt(self.J_resnet34(torch.cat([outI, outE, outF], dim=1)))))\n",
    "\n",
    "        outC_pooled = self.K_in_block(outC)\n",
    "        outD_pooled = self.K_in_block(outD)\n",
    "        outK = self.K_block_relu(self.K_block_bn(self.K_block_convt(self.K_resnet34(torch.cat([outJ, outC_pooled, outD_pooled], dim=1)))))\n",
    "        #print(\"outK\", outK.size())\n",
    "\n",
    "        outA2 = self.L0_block_conv(outA)\n",
    "        outB2 = self.L0_block_conv(outB)\n",
    "        #print(\"outB2\", outB2.size())\n",
    "        #print(\"outK\", outK.size())\n",
    "        outK_upsampled =F.interpolate(outK, size=(193, 193), mode='bilinear', align_corners=False)\n",
    "        outL = self.L2_block_relu(self.L2_block_bn(self.L2_block_convt(torch.cat([self.L1_block_relu(self.L1_block_bn(self.L1_block_bn(torch.cat([outK_upsampled, outB2], dim=1)))), outA2], dim=1))))\n",
    "        #print(\"outL\", outL.size())\n",
    "\n",
    "        outM = self.M_avg_pool(self.M_block_relu(self.M_block_bn(self.M_block_convt(outL))))\n",
    "        #print(\"outM\", outM.size())\n",
    "\n",
    "        outN= self.classifier(outM)\n",
    "        # print(\"outL\", outL.size())\n",
    "        \n",
    "        bbox_output = self.bbox_regressor(outM)\n",
    "        return outN,bbox_output\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "#print(model)\n",
    "\n",
    "#summary(model, input_size=((32, 3, 128, 256), (32, 3, 128, 256)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1605ba2d16425fc6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logdir = \"logs\"\n",
    "experiment = 'learning'\n",
    "\n",
    "# Directory where logs will be saved. \n",
    "log_dir = os.path.join(logdir, experiment)\n",
    "\n",
    "# initiate tensorboard summary writer\n",
    "tb_writer = SummaryWriter(\n",
    "    log_dir = log_dir,\n",
    "    comment = \"EarlyFusion\"\n",
    ")\n",
    "train_accuracy_tag = 'accuracy/train'\n",
    "validation_accuracy_tag = 'accuracy/validation'\n",
    "train_loss_tag = 'loss/train'\n",
    "validation_loss_tag = 'loss/validation'\n",
    "training_ROC_tag='ROC/train'\n",
    "validation_ROC_tag='ROC/validation'\n",
    "training_pearson_tag='pearson/training'\n",
    "validation_pearson_tag='pearson/validation'\n",
    "training_kendal_tag='kendal/training'\n",
    "validation_kendal_tag='kendal/validation'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e880b74aee154d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_model(model, device,epoch, model_dir='models', ):\n",
    "    model_file_name=f'earlyfusion{epoch}.pth'\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "\n",
    "    if device == 'cuda':\n",
    "        model.to('cpu')\n",
    "\n",
    "    # save the state_dict\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    # transfer the model to gpu.\n",
    "    if device == 'cuda':\n",
    "        model.to('cuda')\n",
    "\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24ee8750811f1238"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Mean= [0.485, 0.456, 0.406]\n",
    "Std= [0.229, 0.224, 0.225]\n",
    "common_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(Mean, Std)\n",
    "    ])\n",
    "\n",
    "trainset = kitti_loader(directory=data_root,transform=common_transforms)\n",
    "valset = kitti_loader(directory=validation_root,transform=common_transforms)\n",
    "\n",
    "batch_size = 2\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "valloader= torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr = 0.0001)\n",
    "\n",
    "num_epochs = 100\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)\n",
    "\n",
    "kendall = KendallRankCorrCoef(num_outputs=4).cuda()\n",
    "pearson = PearsonCorrCoef(num_outputs=4).cuda()\n",
    "\n",
    "t_begin = time.time()\n",
    "criterion = nn.MSELoss()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    batch_kendall = []\n",
    "    batch_pearson = []\n",
    "    for i, data in enumerate(trainloader):\n",
    "        input1, input2,label = data\n",
    "\n",
    "        input1 = input1.cuda()\n",
    "        input2 = input2.cuda()\n",
    "        labels = label.cuda().squeeze()\n",
    "        optimizer.zero_grad()\n",
    "        outputs_class,outputs_bbox  = model(input1, input2)\n",
    "\n",
    "        loss = criterion(outputs_bbox, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if loss.item!=None:\n",
    "            running_loss += loss.item()\n",
    "\n",
    "\n",
    "        batch_kendall.append(kendall (outputs_bbox, labels.float()))\n",
    "        batch_pearson.append(pearson(outputs_bbox, labels.float()))\n",
    "\n",
    "    print(batch_kendall)\n",
    "    kendall_sum = torch.stack(batch_kendall).sum(dim=0)  # sum size of batch\n",
    "    kendall_mean = kendall_sum / len(trainloader)  # devide len batch\n",
    "    kendall_mean_scalar = torch.mean(kendall_mean).item()  \n",
    "    print(\"kendall_mean_scalar\",kendall_mean_scalar)\n",
    "    pearson_sum = torch.stack(batch_pearson).sum(dim=0)\n",
    "    pearson_mean = pearson_sum / len(trainloader)\n",
    "    pearson_mean_scalar = torch.mean(pearson_mean).item()\n",
    "    print(\"pearson_mean_scalar\",pearson_mean_scalar)\n",
    "    tb_writer.add_scalar(tag=train_loss_tag, \n",
    "             scalar_value=running_loss,\n",
    "             global_step=epoch)\n",
    "    \n",
    "    tb_writer.add_scalar(tag=training_kendal_tag, \n",
    "             scalar_value=kendall_mean_scalar,\n",
    "             global_step=epoch)\n",
    "    tb_writer.add_scalar(tag=training_pearson_tag, \n",
    "             scalar_value=pearson_mean_scalar,\n",
    "             global_step=epoch)\n",
    "\n",
    "    elapsed_time = time.time() - t_begin\n",
    "    speed_epoch = elapsed_time / (epoch + 1)\n",
    "    eta = speed_epoch * num_epochs - elapsed_time\n",
    "\n",
    "    print(\n",
    "        \"Elapsed {:.2f}s, {:.2f} s/epoch, ets {:.2f}s\".format(\n",
    "            elapsed_time, speed_epoch, eta\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1},Loss: {running_loss} \")\n",
    "\n",
    "    if epoch % 5 == 0 :\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        \n",
    "        pearson_val = PearsonCorrCoef(num_outputs=4).cuda()\n",
    "        kendall_val = KendallRankCorrCoef(num_outputs=4).cuda()\n",
    "        batch_kendall_val = []\n",
    "        batch_pearson_val = []\n",
    "        for batch_idx, (data) in enumerate(valloader):\n",
    "            input1, input2,label = data\n",
    "            input1 = input1.cuda()\n",
    "            input2 = input2.cuda()\n",
    "            labels = label.cuda().squeeze()\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                outputs_class,outputs_bbox  = model(input1, input2)\n",
    "\n",
    "            batch_kendall_val.append(kendall (outputs_bbox, labels.float()))\n",
    "            batch_pearson_val.append(pearson(outputs_bbox, labels.float()))\n",
    "        \n",
    "        kendall_sum_val = torch.stack(batch_kendall_val).sum(dim=0)\n",
    "        kendall_mean_val = kendall_sum_val / len(valloader)\n",
    "        kendall_mean_val_scalar = torch.mean(kendall_mean_val).item()\n",
    "        \n",
    "        pearson_sum_val = torch.stack(batch_pearson_val).sum(dim=0)\n",
    "        pearson_mean_val= pearson_sum_val/ len(valloader)\n",
    "        pearson_mean_val_scalar = torch.mean(pearson_sum_val).item()\n",
    "\n",
    "        tb_writer.add_scalar(tag=validation_loss_tag, \n",
    "             scalar_value=val_loss,\n",
    "             global_step=epoch)\n",
    "        tb_writer.add_scalar(tag=validation_kendal_tag, \n",
    "                 scalar_value=kendall_mean_val_scalar,\n",
    "                 global_step=epoch)\n",
    "        tb_writer.add_scalar(tag=validation_pearson_tag, \n",
    "                 scalar_value=pearson_mean_val_scalar,\n",
    "                 global_step=epoch)\n",
    "\n",
    "        save_model(model, device=device,epoch=epoch)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Finished Training\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc3d84a5e408a98f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "951acb51abe1ec4b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
